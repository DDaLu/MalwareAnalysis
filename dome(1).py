# -*- coding:utf-8 -*-
from sklearn.feature_extraction.text import CountVectorizer
import os
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn import svm
from sklearn import tree
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.feature_extraction.text import TfidfTransformer
# 训练感知机模型
from sklearn.linear_model import Perceptron
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import tflearn
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.conv import conv_1d, global_max_pool
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.merge_ops import merge
from tflearn.layers.estimator import regression
from tflearn.data_utils import to_categorical, pad_sequences
from sklearn.neural_network import MLPClassifier
from tflearn.layers.normalization import local_response_normalization
from tensorflow.contrib import learn
#import gensim
import re
#from gensim.models import Doc2Vec
#from gensim.models.doc2vec import Doc2Vec, LabeledSentence
from random import shuffle
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import scale
from sklearn.metrics import classification_report
import xgboost as xgb
# from hmmlearn import hmm
import matplotlib.pyplot as plt
from tflearn.layers.recurrent import bidirectional_rnn, BasicLSTMCell
from sklearn.preprocessing import StandardScaler

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 隐藏提示警告


######
def load_files_from_dir(dir):
    import glob
    files = glob.glob(dir)
    result = []
    for file in files:
        # print "Load file %s" % file
        with open(file) as f:
            lines = f.readlines()
            lines_to_line = " ".join(lines)
            lines_to_line = re.sub(r"[APT|Crypto|Locker|Zeus]", ' ', lines_to_line, flags=re.I)
            result.append(lines_to_line)
    return result


def load_files():
    # /data/malware/MalwareTrainingSets-master/trainingSets
    malware_class = ['APT1', 'Crypto', 'Locker', 'Zeus']
    x = []
    y = []
    for i, family in enumerate(malware_class):
        dir = r"F:\ProgramAnalysis\MalwareTrainingSets_master\trainingSets\%s\*" % family
        print("Load files from %s index %d" % (dir, i))
        v = load_files_from_dir(dir)
        x += v
        y += [i] * len(v)
    print("Loaded files %d" % len(x))
    return x, y


def get_feature_text():
    x, y = load_files()
    max_features = 1000

    vectorizer = CountVectorizer(
        decode_error='ignore',
        ngram_range=(2, 2),
        strip_accents='ascii',
        max_features=max_features,
        stop_words='english',
        max_df=1.0,
        min_df=1,
        token_pattern=r'\b\w+\b',
        binary=True)
    # print (vectorizer)
    x = vectorizer.fit_transform(x)

    transformer = TfidfTransformer(smooth_idf=False)
    x = transformer.fit_transform(x)
    # 非常重要 稀疏矩阵转换成矩阵
    x = x.toarray()
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4)
    return x_train, x_test, y_train, y_test


############
def do_perceptron(x_train, x_test, y_train, y_test):
    clf = Perceptron(n_iter=40, eta0=0.1, random_state=0)
    clf.fit(x_train, y_train)
    y_pred = clf.predict(x_test)
    print(classification_report(y_test, y_pred))


def do_logisticregression(x_train, x_test, y_train, y_test):
    clf = LogisticRegression(C=1000.0, random_state=0)
    clf.fit(x_train, y_train)
    y_pred = clf.predict(x_test)
    # y_pred=clf.predict_proba(x_test)
    print(classification_report(y_test, y_pred))


def do_knn(x_train, x_test, y_train, y_test):
    clf = KNeighborsClassifier()
    clf.fit(x_train, y_train)
    y_pred = clf.predict(x_test)
    # y_pred=knn.predict_proba(iris_x_test)
    print(classification_report(y_test, y_pred))


def do_decisiontree(x_train, x_test, y_train, y_test):
    clf = tree.DecisionTreeClassifier()
    clf.fit(x_train, y_train)
    y_pred = clf.predict(x_test)
    print(classification_report(y_test, y_pred))


def do_randomforest(x_train, x_test, y_train, y_test):
    clf = RandomForestClassifier(n_estimators=10)
    clf.fit(x_train, y_train)
    y_pred = clf.predict(x_test)
    # y_pred=knn.predict_proba(iris_x_test)
    print(classification_report(y_test, y_pred))


def do_naive_bayes(x_train, x_test, y_train, y_test):
    clf = GaussianNB()
    clf.fit(x_train, y_train)
    y_pred = clf.predict(x_test)
    # y_pred = clf.predict_proba(x_test)
    print(classification_report(y_test, y_pred))


def do_svm(x_train, x_test, y_train, y_test):
    from sklearn.svm import SVC
    clf = svm.SVC(kernel='linear', C=1.0)
    clf.fit(x_train, y_train)
    y_pred = clf.predict(x_test)
    print(classification_report(y_test, y_pred))


def do_xgboost(x_train, x_test, y_train, y_test):
    xgb_model = xgb.XGBClassifier().fit(x_train, y_train)
    y_pred = xgb_model.predict(x_test)
    print(classification_report(y_test, y_pred))


def do_mlp(x_train, x_test, y_train, y_test):
    clf = MLPClassifier(solver='lbfgs',
                        alpha=1e-5,
                        hidden_layer_sizes=(10, 4),
                        random_state=1)
    clf.fit(x_train, y_train)
    y_pred = clf.predict(x_test)
    print(classification_report(y_test, y_pred))


######

def do_cnn_1d(trainX, testX, trainY, testY):
    #
    trainX = trainX * 10
    testX = testX * 10
    '''
    StandardScaler().fit_transform(trainX)[:,:]
    StandardScaler().fit_transform(testX)[:,:]
    '''
    testYYY = np.array(testY)
    # Converting labels to binary vectors
    trainY = to_categorical(trainY, nb_classes=4)
    testY = to_categorical(testY, nb_classes=4)
    # Building convolutional network
    network = input_data(shape=[None, 1000], name='input')
    network = tflearn.embedding(network, input_dim=1000000, output_dim=128, validate_indices=False)
    branch1 = conv_1d(network, 128, 8, padding='valid', activation='relu', regularizer="L2")
    branch2 = conv_1d(network, 128, 8, padding='valid', activation='relu', regularizer="L2")
    branch3 = conv_1d(network, 128, 8, padding='valid', activation='relu', regularizer="L2")
    branch4 = conv_1d(network, 128, 8, padding='valid', activation='tanh', regularizer="L2")
    branch5 = conv_1d(network, 128, 8, padding='valid', activation='tanh', regularizer="L2")
    branch6 = conv_1d(network, 128, 8, padding='valid', activation='tanh', regularizer="L2")
    network = merge([branch1, branch2, branch3, branch4, branch5, branch6], mode='concat', axis=1)
    #
    network = tf.expand_dims(network, 2)
    network = global_max_pool(network)
    network = fully_connected(network, 128, activation='relu')
    network = fully_connected(network, 128, activation='tanh')
    network = fully_connected(network, 128, activation='tanh')
    network = fully_connected(network, 4, activation='softmax')
    network = regression(network, optimizer='adam', learning_rate=0.001,
                         loss='categorical_crossentropy', name='target')
    # Training
    model = tflearn.DNN(network, tensorboard_verbose=0)
    model.fit(trainX, trainY, n_epoch=1, shuffle=True, validation_set=(testX, testY),
              show_metric=True, batch_size=100, run_id="malware")
    # 使用训练好的模型进行结果预测
    y_pred = model.predict(testX)
    print(type(testX))
    print(testX)
    print(trainX)
    print(y_pred)
    y_pred = np.argmax(y_pred, 1)
    print(y_pred)
    print(testYYY)
    print(classification_report(testYYY, y_pred))


###

def do_rnn(trainX, testX, trainY, testY):
    #
    trainX = trainX * 10
    testX = testX * 10
    '''
    StandardScaler().fit_transform(trainX)[:,:]
    StandardScaler().fit_transform(testX)[:,:]
    '''
    testYYY = np.array(testY)
    # Converting labels to binary vectors
    trainY = to_categorical(trainY, nb_classes=4)
    testY = to_categorical(testY, nb_classes=4)
    # Building convolutional network
    network = input_data(shape=[None, 1000], name='input')
    network = tflearn.embedding(network, input_dim=1000000, output_dim=128, validate_indices=False)
    network = tflearn.lstm(network, 256, dropout=0.8)
    #
    '''
    network = fully_connected(network, 128, activation='relu')
    network = fully_connected(network, 128, activation='tanh')
    network = fully_connected(network, 128, activation='tanh')
    '''
    network = fully_connected(network, 4, activation='softmax')
    network = regression(network, optimizer='adam', learning_rate=0.001,
                         loss='categorical_crossentropy', name='target')
    # Training
    model = tflearn.DNN(network, tensorboard_verbose=0)
    model.fit(trainX, trainY, n_epoch=1, shuffle=True, validation_set=(testX, testY),
              show_metric=True, batch_size=100, run_id="malware")
    # 使用训练好的模型进行结果预测
    y_pred = model.predict(testX)
    y_pred2 = model.predict_label(x)
    print(testX)
    print(trainX)
    print(y_pred)
    print(y_pred2)
    y_pred = np.argmax(y_pred, 1)
    print(y_pred)
    print(testYYY)
    print(classification_report(testYYY, y_pred))


###


if __name__ == "__main__":
    print("Hello malware")

    print ("--- svm")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_svm(x_train, x_test, y_train, y_test)


    print ("--- xgboost")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_xgboost(x_train, x_test, y_train, y_test)


    print ("--- mlp")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_mlp(x_train, x_test, y_train, y_test)

    print ("--- cnn_1d")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_cnn_1d(x_train, x_test, y_train, y_test)

    print ("--- rnn")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_rnn(x_train, x_test, y_train, y_test)

    print ("--- do_knn")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_knn(x_train, x_test, y_train, y_test)


    print ("--- do_naive_bayes")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_naive_bayes(x_train, x_test, y_train, y_test)

    print ("--- do_naive_bayes")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_decisiontree(x_train, x_test, y_train, y_test)

    print ("--- do_perceptron")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_perceptron(x_train, x_test, y_train, y_test)

    print ("--- do_logisticregression")
    x_train, x_test, y_train, y_test=get_feature_text()
    do_logisticregression(x_train, x_test, y_train, y_test)

    print("--- do_randomforest")
    x_train, x_test, y_train, y_test = get_feature_text()
    do_randomforest(x_train, x_test, y_train, y_test)
