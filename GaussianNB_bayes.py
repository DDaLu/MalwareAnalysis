import glob
import re
from sklearn.model_selection import cross_val_score

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB,np
from sklearn.metrics import classification_report


# 加载文件路径
def load_files_from_dir(dir):
    files = glob.glob(dir)
    result = []
    for file in files:
        print(" %s\n" % file)
        with open(file) as f:
            lines = f.readline()
            lines_to_line = " ".join(lines)
            lines_to_line = re.sub(r"[APT1|Crypto|Locker|Zeus]", ' ', lines_to_line, flags=re.I)
            result.append(lines_to_line)
    return result


# 加载文件
def load_files(dir):
    malware_class = ['APT1', 'Crypto', 'Locker', 'Zeus']
    x = []
    y = []
    for i, family in enumerate(malware_class):
        print("Load files from %s" % dir)
        v = load_files_from_dir(dir)
        x += v
        y += [i] * len(v)
    return x, y


if __name__ == '__main__':
    malware_class = ['APT1', 'Crypto', 'Locker', 'Zeus']
    train_x = []
    train_y = []
    test_x = []
    test_y = []
    for i, family in enumerate(malware_class):
        dir = r'F:\ProgramAnalysis\MalwareTrainingSets_master\GaussianNB_Sets\TrainingSets\%s\*' % family
        print("Load files from %s" % dir)
        v = load_files_from_dir(dir)
        train_x += v
        train_y += [i] * len(v)

    train_vectorizer = CountVectorizer(
        decode_error='ignore',
        ngram_range=(2, 2),
        strip_accents='ascii',
        max_features=1000,
        stop_words='english',
        max_df=1.0,
        min_df=1,
        token_pattern=r'\b\w+\b',
        binary=False
    )
    x1 = train_vectorizer.fit_transform(train_x).toarray()
    vocabulary = train_vectorizer.vocabulary_

    for i, family in enumerate(malware_class):
        dir = r'F:\ProgramAnalysis\MalwareTrainingSets_master\GaussianNB_Sets\TestSets\%s\*' % family
        print("Load files from %s" % dir)
        v = load_files_from_dir(dir)
        test_x += v
        test_y += [i] * len(v)

    test_vectorizer = CountVectorizer(
        decode_error='ignore',
        ngram_range=(2, 2),
        strip_accents='ascii',
        max_features=1000,
        stop_words='english',
        max_df=1.0,
        min_df=1,
        token_pattern=r'\b\w+\b',
        binary=False,
        vocabulary = vocabulary
    )
    x2 = test_vectorizer.fit_transform(test_x).toarray()
    x = np.concatenate((x1,x2))
    y = np.concatenate((train_y,test_y))
    clf = GaussianNB()
    print(cross_val_score(clf,x,y,n_jobs=-1,cv=3))


